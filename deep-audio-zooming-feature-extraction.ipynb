{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eafab3c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-23T18:42:20.541175Z",
     "iopub.status.busy": "2026-02-23T18:42:20.540848Z",
     "iopub.status.idle": "2026-02-23T18:42:21.752163Z",
     "shell.execute_reply": "2026-02-23T18:42:21.751013Z"
    },
    "papermill": {
     "duration": 1.217567,
     "end_time": "2026-02-23T18:42:21.754584",
     "exception": false,
     "start_time": "2026-02-23T18:42:20.537017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57ace62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T18:42:21.759831Z",
     "iopub.status.busy": "2026-02-23T18:42:21.759301Z",
     "iopub.status.idle": "2026-02-23T18:42:25.520236Z",
     "shell.execute_reply": "2026-02-23T18:42:25.519103Z"
    },
    "papermill": {
     "duration": 3.766459,
     "end_time": "2026-02-23T18:42:25.522637",
     "exception": false,
     "start_time": "2026-02-23T18:42:21.756178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e63511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T18:42:25.527522Z",
     "iopub.status.busy": "2026-02-23T18:42:25.527006Z",
     "iopub.status.idle": "2026-02-23T18:42:25.542944Z",
     "shell.execute_reply": "2026-02-23T18:42:25.541673Z"
    },
    "papermill": {
     "duration": 0.021082,
     "end_time": "2026-02-23T18:42:25.545177",
     "exception": false,
     "start_time": "2026-02-23T18:42:25.524095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, n_fft=512, hop_length=256, sample_rate= 16000, mic_positions = None, speed_of_sound = 343):\n",
    "\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length  = hop_length\n",
    "        self.sample_rate = sample_rate\n",
    "        self.mic_positions = mic_positions  #mic_positions (num_mics,3)\n",
    "        self.speed_of_sound = speed_of_sound\n",
    "\n",
    "        self.freqs = np.fft.rfftfreq(n_fft, 1/sample_rate)\n",
    "\n",
    "    def stft(self, waveform):\n",
    "        window = torch.hann_window(self.n_fft).to(waveform.device)\n",
    "        stft_complex = torch.stft(waveform, slef.n_fft, self.hop_length, window = window, return_complex = True)\n",
    "\n",
    "        return stft_complex\n",
    "\n",
    "    def lps(self, stft_complex, ref_channel = 0):\n",
    "        power = stft_complex[:,real_channel].abs()**2 + 1e-8\n",
    "        return torch.log(power)\n",
    "\n",
    "    def ipd(self, stft_complex, ref_channel=0):\n",
    "        Y_ref = stft_complex[:,ref_channel]\n",
    "        cross = torch.conj(Y_ref.unsqueeze(1))\n",
    "\n",
    "        ipd = cross / (cross.abs() + 1e-8)\n",
    "        return ipd\n",
    "\n",
    "    def theoretical_ipd(self, azimuth, elevation = 0):\n",
    "\n",
    "        u = np.array([np.cos(elevation)*np.cos(azimuth), np.cos(elevation)*np.azimuth],np.sin(elevation))\n",
    "\n",
    "        tau = np.dot(self.mic_positions[1:] - self.mic_positions[0],u) / self.speed_of_sound\n",
    "\n",
    "        omega = 2*np.pi*self.freqs\n",
    "\n",
    "        ipd_theory = np.exp(-1j * np.outer(omega, tau))\n",
    "\n",
    "        return torch.tensor(ipd_theory.T, dtype=torch.complex(64))\n",
    "\n",
    "    def directional_features(self, stft_complex, azimuth_grid, fov_az_range, elevation=0):\n",
    "#azimuth grd - list or a tensor of candidate azimuths (radians to sample)\n",
    "#fov_az_range - [az_min, az_max] radians of target FOV\n",
    "        \n",
    "        \n",
    "        batch, ch, freq, time = stft_complex.shape\n",
    "        device = stft_complex.device\n",
    "\n",
    "        ipd_obs = self.ipd(stft_complex)\n",
    "        #computing ipd of refsand other mics\n",
    "        num_candidates = len(azimuth_grid)\n",
    "        ipd_theory_all = []\n",
    "\n",
    "        for az in azimuth_grid:\n",
    "            ipd_theory = self.theoretical_ipd(az, elevation).to(device)\n",
    "            ipd_theory_all.append(ipd_theory)\n",
    "        \n",
    "        ipd_theory_all  = torch.stack(ipd_theory_all, dim=0)\n",
    "\n",
    "        ipd_theory_exp = ipd_theory_all.unsqueeze(1).unsqueeze(-1)\n",
    "\n",
    "        #computing cosine similarity\n",
    "        torch.real(ipd_obs.unsqueeze(1) * torch.conj(ipd_theory_exp)).sum(dim =2)\n",
    "\n",
    "        similarity = similarity  / (ipd_obs.shape[1] + 1e-8)\n",
    "        #maximizing  over candidates inside FOV\n",
    "\n",
    "        inside_mask = (torch.tensor(azimuth_grid) >= fov_az_range[1])\n",
    "        inside_mask = inside_mask.to(device)\n",
    "\n",
    "        if inside_mask.any():\n",
    "            D_in = similarity[:, inside_mask, :, :].max(dim=1)[0]\n",
    "        else:\n",
    "            D_in = torch.zeros(batch, freq, time, device = device)\n",
    "\n",
    "        outside_mask = ~inside_mask\n",
    "        if outside_mask.any():\n",
    "            D_out = similarity[:, outside_mask, :, :].max(dim=1)[0]\n",
    "        else:\n",
    "            D_out = torch.zeros(batch, freq, time, device=device)\n",
    "        return D_in, D_out\n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.802785,
   "end_time": "2026-02-23T18:42:26.570420",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-23T18:42:16.767635",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
